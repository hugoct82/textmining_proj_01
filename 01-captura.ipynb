{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dado que algunas paginas no permiten scrapear...\n",
    "\n",
    "Vamos a utilizar beatifulSoap para poder hacerlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primera versión\n",
    "\n",
    "Extracción de noticias del diario el cronista, utilizando fuentes RSS.\n",
    "\n",
    "Al final se indica la cantidad de dastos extraidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title Link  \\\n",
      "0  Volvió a subir el dólar y el BCRA compró el mo...        \n",
      "1  Dieta Keto: los alimentos y bebidas que tenés ...        \n",
      "2  Macri asumió la presidencia del PRO: cuál fue ...        \n",
      "3  Dólar blue HOY: a cuánto cerró la cotización e...        \n",
      "4  Aumenta el subte: la justicia porteña dio marc...        \n",
      "\n",
      "                                         Description  \\\n",
      "0  Los dólares financieros avanzaron hasta 1% y e...   \n",
      "1  Conocer los alimentos prohibidos en una dieta ...   \n",
      "2  El exmandatario volvió a la conducción formal ...   \n",
      "3  Estos son los datos más importantes a los que ...   \n",
      "4  La jueza Elena Liberatori recibió la informaci...   \n",
      "\n",
      "                Publication Date  \n",
      "0  Thu, 16 May 2024 22:02:00 GMT  \n",
      "1  Thu, 16 May 2024 22:00:00 GMT  \n",
      "2  Thu, 16 May 2024 21:45:00 GMT  \n",
      "3  Thu, 16 May 2024 21:08:27 GMT  \n",
      "4  Thu, 16 May 2024 20:58:35 GMT  \n",
      "Cantidad de registros: 100\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "\n",
    "# URL de la fuente RSS\n",
    "url = 'https://www.cronista.com/files/rss/news.xml'\n",
    "\n",
    "# Definir encabezados HTTP para simular una solicitud de navegador\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "}\n",
    "\n",
    "# Intentar obtener los datos de la fuente RSS con los encabezados\n",
    "response = requests.get(url, headers=headers)\n",
    "response.raise_for_status()  # Asegurarse que la solicitud fue exitosa\n",
    "\n",
    "# Parsear el contenido usando lxml-xml como parser\n",
    "soup = bs(response.content, 'lxml-xml')\n",
    "\n",
    "# Encontrar todos los elementos 'item'\n",
    "items = soup.find_all('item')\n",
    "\n",
    "data = []\n",
    "\n",
    "for item in items:\n",
    "    title = item.find('title').text if item.find('title') else None\n",
    "    link = item.find('link').next_sibling.strip() if item.find('link') else None\n",
    "    description = item.find('description').text if item.find('description') else None\n",
    "    pub_date = item.find('pubDate').text if item.find('pubDate') else None\n",
    "    \n",
    "\n",
    "    # Añade los datos extraídos a la lista como un diccionario\n",
    "    data.append({\n",
    "        'Title': title,\n",
    "        'Link': link,\n",
    "        'Description': description,\n",
    "        'Publication Date': pub_date\n",
    "        })\n",
    "\n",
    "\n",
    "# Crea el DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Muestra el DataFrame\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "print(f\"Cantidad de registros: {len(items)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versión 2\n",
    "Similar a la anterior, solo que se suma la URL de la noticia\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title Link  \\\n",
      "0  Las conservas que son ideales para una picada ...        \n",
      "\n",
      "                                         Description  \\\n",
      "0  Explora cómo estos modestos acompañantes puede...   \n",
      "\n",
      "                Publication Date  \n",
      "0  Wed, 15 May 2024 22:59:00 GMT  \n",
      "Cantidad de registros: 100\n"
     ]
    }
   ],
   "source": [
    "# Usar comprensión de lista para crear una lista de diccionarios con la información de cada ítem\n",
    "articles = [{\n",
    "    'title': item.find('title').text if item.find('title') else \"No title provided\",\n",
    "    'link': item.find('link').text.strip() if item.find('link') and item.find('link').text else \"No link provided\",\n",
    "    'description': item.find('description').text if item.find('description') else \"No description provided\",\n",
    "    'pub_date': item.find('pubDate').text if item.find('pubDate') else \"No publication date provided\"\n",
    "} for item in items]\n",
    "\n",
    "data = []\n",
    "\n",
    "# Añade los datos extraídos a la lista como un diccionario\n",
    "data.append({\n",
    "    'Title': title,\n",
    "    'Link': link,\n",
    "    'Description': description,\n",
    "    'Publication Date': pub_date\n",
    "    })\n",
    "\n",
    "# Crea el DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Muestra el DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Imprimir la cantidad de registros\n",
    "print(f\"Cantidad de registros: {len(articles)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping https://www.cronista.com/Seccion/Economia/: 403 Client Error: Forbidden for url: https://www.cronista.com/Seccion/Economia/\n",
      "              newspaper                                              title  \\\n",
      "0   www.lanacion.com.ar  Licitación.Aceleran el traspaso de pesos al Te...   \n",
      "1   www.lanacion.com.ar  Se extiende hasta el domingo.El Hot Sale regis...   \n",
      "2   www.lanacion.com.ar  Cuarto consecutivo.En abril hubo otro superávi...   \n",
      "3   www.lanacion.com.ar  Dólar.El Banco Central hizo la mayor compra de...   \n",
      "4   www.lanacion.com.ar  \"Encubre la dolarización\".Economistas vinculad...   \n",
      "5   www.lanacion.com.ar  “De Mónaco a Buenos Aires”.Las oportunidades d...   \n",
      "6   www.lanacion.com.ar  Dolarización.El Fondo dio una definición clave...   \n",
      "7   www.lanacion.com.ar  Recesión.Por la menor actividad, crecen los de...   \n",
      "8   www.lanacion.com.ar  Bajas temperaturas.Les cortan el GNC a 113 est...   \n",
      "9   www.lanacion.com.ar  Maestro de empresarios.Murió un referente del ...   \n",
      "10  www.lanacion.com.ar  Cambio de rumbo.La ejecutiva que se incorporó ...   \n",
      "\n",
      "                                                 link  \\\n",
      "0   /economia/se-acelero-el-traspaso-de-pesos-al-t...   \n",
      "1   /economia/se-extiende-el-hot-sale-que-registro...   \n",
      "2   /economia/caputo-confirmo-que-en-abril-se-regi...   \n",
      "3   /economia/el-banco-central-hizo-la-mayor-compr...   \n",
      "4   /economia/economistas-vinculados-a-martin-guzm...   \n",
      "5   /economia/negocios/las-oportunidades-del-negoc...   \n",
      "6   /economia/el-fondo-dio-una-definicion-clave-so...   \n",
      "7   /economia/por-la-menor-actividad-crecen-los-de...   \n",
      "8   /economia/les-cortan-el-gnc-a-113-estaciones-d...   \n",
      "9   /economia/jorge-aceiro-maestro-de-empresarios-...   \n",
      "10  /economia/negocios/la-ejecutiva-que-se-incorpo...   \n",
      "\n",
      "                description             pub_date  \n",
      "0   No description provided  2024-05-16 20:16:50  \n",
      "1   No description provided  2024-05-16 20:16:50  \n",
      "2   No description provided  2024-05-16 20:16:50  \n",
      "3   No description provided  2024-05-16 20:16:50  \n",
      "4   No description provided  2024-05-16 20:16:50  \n",
      "5   No description provided  2024-05-16 20:16:50  \n",
      "6   No description provided  2024-05-16 20:16:50  \n",
      "7   No description provided  2024-05-16 20:16:50  \n",
      "8   No description provided  2024-05-16 20:16:50  \n",
      "9   No description provided  2024-05-16 20:16:50  \n",
      "10  No description provided  2024-05-16 20:16:50  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def scrape_news(urls):\n",
    "    data = []  # Lista para almacenar todos los datos recopilados\n",
    "\n",
    "    for url in urls:\n",
    "        try:\n",
    "            # Realizar la petición HTTP a la página\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()  # Asegurar que la respuesta es exitosa\n",
    "\n",
    "            # Parsear el contenido HTML de la página\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Encontrar todos los elementos que contengan información de artículos\n",
    "            items = soup.find_all('article')\n",
    "\n",
    "            # Extraer datos de cada artículo\n",
    "            articles = [{\n",
    "                'newspaper': url.split('/')[2],  # Extraer el nombre del dominio como nombre del diario\n",
    "                'title': item.find('h2').get_text(strip=True) if item.find('h2') else \"No title provided\",\n",
    "                'link': item.find('a')['href'] if item.find('a') else \"No link provided\",\n",
    "                'description': item.find('p').get_text(strip=True) if item.find('p') else \"No description provided\",\n",
    "                'pub_date': item.find('time').get_text(strip=True) if item.find('time') else datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") \n",
    "            } for item in items]\n",
    "\n",
    "            # Agregar los artículos de esta página al listado general\n",
    "            data.extend(articles)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping {url}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Convertir la lista de diccionarios a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Ejemplo de uso:\n",
    "urls = [\n",
    "    'https://www.lanacion.com.ar/economia/',\n",
    "    'https://www.ambito.com/economia',\n",
    "    'https://www.cronista.com/Seccion/Economia/',\n",
    "    'https://eleconomista.com.ar/',\n",
    "    'https://www.infobae.com/economia/',\n",
    "    'https://www.forbesargentina.com/temas/finanzas-t17'\n",
    "]\n",
    "\n",
    "news_df = scrape_news(urls)\n",
    "print(news_df.head(11))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versión final\n",
    "\n",
    "Trabajaremos sobre noticias de indole economica, utilizaremos la fuentes RSS, por disponer de mas contenido a diferencia de la extracción de titulos y subtitulos.\n",
    "\n",
    "Pasos:\n",
    "\n",
    "1 - Buscar fuentes de diarios que traten noticias economicas y extracción de esos datos. Ok\n",
    "\n",
    "2 - Generar el proceso de extracción 1 vez al día. OK -  Analizar la posibilidad de realizarlo en automatico\n",
    "\n",
    "3 - Generar un analisis de sentimiento usando libreria de huggings face - \n",
    "\n",
    "4 - Generar una clasificación de temas en politica economica e industrias emergentes y mercado agro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Fuente de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se podrá trabajar con las fuentes RSS de economia internacionales y nacionales\n",
    "\n",
    "#### Internacionales\n",
    "https://es.mercopress.com/rss/\n",
    "\n",
    "https://www.oecd.org/index.xml\n",
    "\n",
    "https://www.cnbc.com/id/20910258/device/rss\n",
    "\n",
    "https://feeds.washingtonpost.com/rss/business?itid=lk_inline_manual_36\n",
    "\n",
    "https://www.reutersagency.com/feed/?taxonomy=best-sectors&post_type=best\n",
    "\n",
    "https://www.federalreserve.gov/feeds/press_all.xml\n",
    "\n",
    "https://www.bbc.com/mundo/temas/economia/index.xml\n",
    "\n",
    "\n",
    "#### Nacionales\n",
    "https://www.perfil.com/feed/economia\n",
    "\n",
    "https://www.clarin.com/rss/economia/\n",
    "\n",
    "https://www.ambito.com/rss/pages/economia.xml\n",
    "\n",
    "https://www.ambito.com/rss/pages/negocios.xml\n",
    "\n",
    "https://www.iprofesional.com/rss/economia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción de fuente de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Función para extraer los datos co manejo de excepción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def fetch_rss_data(rss_urls):\n",
    "    all_data = []\n",
    "    failed_sources = []  # Lista para almacenar las fuentes que fallan\n",
    "    \n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "    }\n",
    "\n",
    "    for url in rss_urls:\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            response.raise_for_status()  # Asegura que la solicitud fue exitosa\n",
    "            \n",
    "            soup = bs(response.content, 'lxml-xml')\n",
    "            diario = url.split('/')[2]  # Extraer nombre del diario del dominio de la URL\n",
    "\n",
    "            items = soup.find_all('item')\n",
    "            for item in items:\n",
    "                title = item.find('title').text if item.find('title') else None\n",
    "                description = item.find('description').text if item.find('description') else None\n",
    "                pub_date = item.find('pubDate').text if item.find('pubDate') else datetime.now().strftime(\"%a, %d %b %Y %H:%M:%S %z\")\n",
    "                \n",
    "                all_data.append({\n",
    "                    'diario': diario,\n",
    "                    'titulo': title,\n",
    "                    'contenido': description,\n",
    "                    'fecha de extracción': pub_date\n",
    "                })\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Falla en el proceso RSS desde: {url}, Error: {str(e)}\")\n",
    "            failed_sources.append(url)  # Agregar URL a la lista de fuentes fallidas\n",
    "\n",
    "    df = pd.DataFrame(all_data)\n",
    "    return df, failed_sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpieza de html\n",
    "\n",
    "Se analiza la estructura de los html para decidir que es lo que se requiere limpiar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def clean_html(content):\n",
    "    # Verificar si el contenido es None\n",
    "    if content is None:\n",
    "        return \"\"\n",
    "    \n",
    "    # Parsear el contenido usando BeautifulSoup\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "    # Eliminar etiquetas indeseadas y sus contenidos\n",
    "    for tag in soup(['script', 'noscript', 'iframe']):\n",
    "        tag.decompose()  # Elimina la etiqueta y su contenido\n",
    "\n",
    "    # Eliminar etiquetas img pero conservar el texto restante\n",
    "    for tag in soup.find_all('img'):\n",
    "        tag.decompose()\n",
    "\n",
    "    # Eliminar etiquetas vacías que pueden haber quedado\n",
    "    for tag in soup(['p', 'li']):\n",
    "        tag.unwrap()\n",
    "    \n",
    "    # Devolver el texto limpio\n",
    "    return soup.get_text(strip=True)  # strip=True elimina espacios adicionales\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noticias Nacionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           diario                                             titulo  \\\n",
      "0  www.ambito.com  La empresa de grifería FV suspendió a 600 trab...   \n",
      "1  www.ambito.com  La actividad industrial cayó 11,7% en el prime...   \n",
      "2  www.ambito.com  Cuáles son los barrios con más oferta de inmue...   \n",
      "3  www.ambito.com  Recesión: las ventas de informática cayeron 33...   \n",
      "4  www.ambito.com  Quién es Lorinc Mészáros, el humilde instalado...   \n",
      "\n",
      "                                           contenido  \\\n",
      "0  <p>La compañía dispuso la suspensión de un gru...   \n",
      "1  <p>A través de su informe mensual, la UIA expr...   \n",
      "2  <p>La oferta de inmuebles disponibles para alq...   \n",
      "3  <p>Los empresarios del sector piden cobrar una...   \n",
      "4  <p>Conocé la historia de uno de los hombres má...   \n",
      "\n",
      "               fecha de extracción  \\\n",
      "0  Thu, 16 May 2024 19:04:00 -0300   \n",
      "1  Thu, 16 May 2024 16:42:10 -0300   \n",
      "2  Thu, 16 May 2024 16:13:00 -0300   \n",
      "3  Thu, 16 May 2024 15:56:00 -0300   \n",
      "4  Thu, 16 May 2024 15:30:00 -0300   \n",
      "\n",
      "                                  contenido_depurado  \n",
      "0  La compañía dispuso la suspensión de un grupo ...  \n",
      "1  A través de su informe mensual, la UIA expresó...  \n",
      "2  La oferta de inmuebles disponibles para alquil...  \n",
      "3  Los empresarios del sector piden cobrar una de...  \n",
      "4  Conocé la historia de uno de los hombres más r...  \n"
     ]
    }
   ],
   "source": [
    "# URLs de fuentes RSS de diarios nacionales\n",
    "rss_urls_nacionales = ['https://www.ambito.com/rss/pages/negocios.xml',\n",
    "            'https://www.perfil.com/feed/economia',\n",
    "            'https://www.clarin.com/rss/economia/',\n",
    "            'https://www.ambito.com/rss/pages/economia.xml',\n",
    "            'https://www.ambito.com/rss/pages/negocios.xml',\n",
    "            'https://www.iprofesional.com/rss/economia']\n",
    "\n",
    "# Extracción\n",
    "dataframe_nacionales, failed_sources_nacionales = fetch_rss_data(rss_urls_nacionales)\n",
    "\n",
    "# Limpieza\n",
    "dataframe_nacionales['contenido_depurado'] = dataframe_nacionales['contenido'].apply(clean_html)\n",
    "\n",
    "# Visualización\n",
    "print(dataframe_nacionales.head())\n",
    "if failed_sources_nacionales:\n",
    "    print(\"Falla de extracción en la/s fueste/s:\", failed_sources_nacionales)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noticias internacionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falla en el proceso RSS desde: https://www.oecd.org/economy/index.xml, Error: 403 Client Error: Forbidden for url: https://www.oecd.org/economy/index.xml\n",
      "Falla en el proceso RSS desde: https://www.reutersagency.com/feed/?taxonomy=best-sectors&post_type=best, Error: 403 Client Error: Forbidden for url: https://www.reutersagency.com/feed/?taxonomy=best-sectors&post_type=best\n",
      "              diario                                             titulo  \\\n",
      "0  es.mercopress.com    Producción de carne sigue mejorando en Paraguay   \n",
      "1  es.mercopress.com  Argentina se prepara para dolarizar su economí...   \n",
      "2  es.mercopress.com  Futuro europeo de Gibraltar podría afectar est...   \n",
      "3  es.mercopress.com  Caen acciones de Petrobras tras la salida de P...   \n",
      "4  es.mercopress.com  Venezuela niega salvoconductos a solicitantes ...   \n",
      "\n",
      "                                           contenido  \\\n",
      "0  <p>\\r\\n\\t   \\t      <img src=\"https://es.merco...   \n",
      "1  <p>\\r\\n\\t   \\t      <img src=\"https://es.merco...   \n",
      "2  <p>\\r\\n\\t   \\t      <img src=\"https://es.merco...   \n",
      "3  <p>\\r\\n\\t   \\t      <img src=\"https://es.merco...   \n",
      "4  <p>\\r\\n\\t   \\t      <img src=\"https://es.merco...   \n",
      "\n",
      "             fecha de extracción  \\\n",
      "0  Thu, 16 May 2024 12:13:00 GMT   \n",
      "1  Thu, 16 May 2024 10:55:00 GMT   \n",
      "2  Thu, 16 May 2024 10:54:00 GMT   \n",
      "3  Thu, 16 May 2024 10:49:00 GMT   \n",
      "4  Thu, 16 May 2024 10:45:00 GMT   \n",
      "\n",
      "                                  contenido_depurado  \n",
      "0  Apenas días después de que se concediera acces...  \n",
      "1  El ministro de Economía argentino, Luis 'Toto'...  \n",
      "2  El futuro de Gibraltar e Irlanda del Norte tra...  \n",
      "3  La decisión del presidente brasileño Luiz Inác...  \n",
      "4  El régimen de Venezuela negó este miércoles la...  \n",
      "Falla de extracción en la/s fueste/s: ['https://www.oecd.org/economy/index.xml', 'https://www.reutersagency.com/feed/?taxonomy=best-sectors&post_type=best']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rss_urls_internacionales = ['https://es.mercopress.com/rss/',\n",
    "                            'https://www.oecd.org/economy/index.xml',\n",
    "                            'https://www.cnbc.com/id/20910258/device/rss',\n",
    "                            'https://feeds.washingtonpost.com/rss/business?itid=lk_inline_manual_36',\n",
    "                            'https://www.reutersagency.com/feed/?taxonomy=best-sectors&post_type=best',\n",
    "                            'https://www.federalreserve.gov/feeds/press_all.xml',\n",
    "                            'https://www.bbc.com/mundo/temas/economia/index.xml'\n",
    "                            ]\n",
    "\n",
    "dataframe_internacionales, failed_sources_internacionales = fetch_rss_data(rss_urls_internacionales)\n",
    "\n",
    "\n",
    "dataframe_internacionales['contenido_depurado'] = dataframe_internacionales['contenido'].apply(clean_html)\n",
    "\n",
    "\n",
    "print(dataframe_internacionales.head())\n",
    "if failed_sources_internacionales:\n",
    "    print(\"Falla de extracción en la/s fueste/s:\", failed_sources_internacionales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardamos los datos con el siguiente formato de salida\n",
    "fecha_nombre_del_archivo.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Obtener la fecha actual en formato de año-mes-día\n",
    "today = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Definir la ruta del directorio donde se guardará el archivo\n",
    "directory = './datos'\n",
    "\n",
    "# Verificar si el directorio existe, si no, crearlo\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datos nacionales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir la ruta completa del archivo incluyendo la carpeta\n",
    "filename_nac = f'{directory}/{today}_noticias_economicas_nacionales.csv'\n",
    "\n",
    "# Guardar el DataFrame en un archivo CSV en la ruta especificada\n",
    "dataframe_nacionales.to_csv(filename_nac, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datos internacionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir la ruta completa del archivo incluyendo la carpeta\n",
    "filename_inter = f'{directory}/{today}_noticias_economicas_internacionales.csv'\n",
    "\n",
    "# Guardar el DataFrame en un archivo CSV en la ruta especificada\n",
    "dataframe_internacionales.to_csv(filename_inter, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Envio de los datos a google drive ver 02-con-drive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env_t01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
